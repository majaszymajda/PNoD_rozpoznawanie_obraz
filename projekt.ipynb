{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONwkHLDQ9vXHWr9n/cPb3S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majaszymajda/PNoD_rozpoznawanie_obraz/blob/main/projekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smpQMYPELuLX"
      },
      "source": [
        "Wczytanie danych\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuIBrybRLMrR"
      },
      "source": [
        "## Zadanie 3\n",
        "Należy sprawdzić jakość jednego z modeli z poprzednich zadań (Naive Bayes, K-NN, Regresja  Logistyczna) na zbiorzeFashionMnist. W tym celu należy wyuczyć model na danych treningowych i ocenić jego jakość na danych testowych w oparciu o poprawność klasyfikacji.W dalszej kolejności należy skonfrontować swój wynik z wynikiem otrzymanym w ramach http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/dla  odpowiadającejmetody i przeanalizować ewentualne różnice.\n",
        "# Zadanie 4 \n",
        "W tym podpunkcie można puścić wodzę fantazji i opracować własny algorytm, bądź algoryt-my do klasyfikacji zbioru FashionMnist. W ramach tego punktu możliwe jest korzystaniez gotowych bibliotek typuKeras, TensorFlow, pytorch, scikitoraz innych. Bardzo istotne jest, żeby opracowany model był uczony na danych treningowych, a oceniany na danych testowych - niedopuszczalne jest wykorzystanie danych testowych w procesie uczenia. W ra-mach danych treningowych można wyodrębnić zbiór walidacyjny na potrzeby selekcji modelu(kalibracji hiperparametrów). Do oceny opracowanej metody należy użyć miary poprawności klasyfikacji,  natomiast  można  badać  inne  miary  jakości,  np.F-Score.  Przez  opracowanie modelu rozumiemy tutaj zastosowanie takich technik augmentacji danych, ekstrakcji cech, doboru modelu i metody uczenia, aby maksymalizować jakość modelu na danych testowych.Wynik działania metody, bądź metod można skonfrontować z wynikami w sekcji Benchmarkna stronie na której udostępniony jest zbiórFasionMnist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMgOnrlXiJDQ"
      },
      "source": [
        "# Zadania do zrealizowania \n",
        "1. Przetworzenie danych\n",
        "2. Zbudowanie modelu \n",
        "3. Trenowanie modelu\n",
        "4. Karmienie Modelu\n",
        "5. Ocena dokładności\n",
        "6. Prognozowanie \n",
        "7. Weryfikacja na danych walidacyjnych\n",
        "8. Wykorzystanie na danych testowych "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8EL2WrWkM4b"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import gzip\n",
        "import time\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import requests\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Ridge, SGDRegressor, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edBiFLmGYE79"
      },
      "source": [
        "# Import plików z githuba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWVod3veqfgZ",
        "outputId": "39c0cfbc-0600-45b1-98aa-d40aeb59dae9"
      },
      "source": [
        "files = [\n",
        "  \"t10k-images-idx3-ubyte.gz\",\n",
        "  \"t10k-labels-idx1-ubyte.gz\",\n",
        "  \"train-images-idx3-ubyte.gz\",\n",
        "  \"train-labels-idx1-ubyte.gz\",\n",
        "]\n",
        "\n",
        "def download_and_save_locally(file):\n",
        "    data = requests.get(f'https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/{file}')\n",
        "    if data.status_code != 200:\n",
        "      print(f\"Blad pobierania pliku {file}\")\n",
        "\n",
        "    with open(file, \"wb\") as f:\n",
        "      f.write(data.content)\n",
        "\n",
        "    print(f\"Pobrano plik {file}\")\n",
        "    # unzipped_content = gzip.open(io.BytesIO(data))\n",
        "   # f'df{file}' = pd.read_csv(unzipped_content, delimiter='\\t')\n",
        " \n",
        "    # df{file}.head()\n",
        "\n",
        "for f in files:\n",
        "    download_and_save_locally(f)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pobrano plik t10k-images-idx3-ubyte.gz\n",
            "Pobrano plik t10k-labels-idx1-ubyte.gz\n",
            "Pobrano plik train-images-idx3-ubyte.gz\n",
            "Pobrano plik train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s50CtfNYRk_"
      },
      "source": [
        "# Przetworzenie danych "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jbmQi0uLriW"
      },
      "source": [
        "def load_mnist(kind):\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    with gzip.open(f'{kind}-labels-idx1-ubyte.gz', 'rb') as lbpath:\n",
        "        # lbpath = pd.read_csv(lbpath)\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                              offset=8)\n",
        "\n",
        "    with gzip.open(f'{kind}-images-idx3-ubyte.gz', 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                              offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqDrYD4B_tUA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3F-oZtBU89m",
        "outputId": "90daf45f-5ccd-46f9-dcb4-2ca49d68be48"
      },
      "source": [
        "X_train, y_train = load_mnist(kind='train')\n",
        "X_test, y_test = load_mnist(kind='t10k')\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train)\n",
        "# klasy podane na gicie numerowane od 0 do 9 \n",
        "class_clothes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "[9 0 0 ... 3 0 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWW3vVqBYX4z"
      },
      "source": [
        "Próba wykorzystania algorytmu napisanego do metody kNN na zajęciach do listy 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdFuuVUyZgBs"
      },
      "source": [
        "def sort_train_labels_knn(Dist, y):\n",
        "    \n",
        "    return y[Dist.argsort(kind='mergesort')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPiDHh5XZsT2"
      },
      "source": [
        "def hamming_distance(X, X_train):\n",
        "    Xrev = 1-X\n",
        "    X = X.astype(int)\n",
        "    X_trainrev = 1 - X_train\n",
        "    X_trainint = X_train.astype(int)\n",
        "    # print(Xrev @ X_trainint.transpose() + X @ X_trainrev.transpose())\n",
        "    return Xrev @ X_trainint.transpose() + X @ X_trainrev.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12I5amvOYgm8"
      },
      "source": [
        "\n",
        "def model_selection_knn(Xval, Xtrain, yval, ytrain, k_values):\n",
        "    \n",
        "    errors = []\n",
        "    srted_et = sort_train_labels_knn(hamming_distance(Xval, Xtrain), ytrain)\n",
        "    best_k = 0\n",
        "    min_er = 1\n",
        "    for k in k_values:\n",
        "        er = classification_error(p_y_x_knn(srted_et, k), yval)\n",
        "        errors.append(er)\n",
        "        if er < min_er:\n",
        "            best_k = k\n",
        "            min_er = er\n",
        "    return min_er, best_k, errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ALR3F1VwHAs"
      },
      "source": [
        "# Ekstrakcja cech\n",
        "zamiast filtrów Haara używam randoma \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cRJzZIG8vLs"
      },
      "source": [
        "np.random.seed(0)\n",
        "val_1_id = np.random.choice(60000, 10000, replace=False)\n",
        "val_2_id = np.random.choice(list(set(range(60000)) - set(val_1_id)), 10000, replace=False)\n",
        "train_id = list(set(range(60000))- set(val_2_id)- set(val_1_id))\n",
        "\n",
        "X_train_1 = X_train[train_id]\n",
        "y_train_1 = y_train[train_id]\n",
        "\n",
        "x_valid_1 = X_train[val_2_id]\n",
        "y_valid_1 = y_train[val_2_id]\n",
        "\n",
        "x_valid_2 = X_train[val_1_id]\n",
        "y_valid_2 = y_train[val_1_id]\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQzUMJxrkrvg"
      },
      "source": [
        "Jako metodę klasyfikacji służąca do budowy modelu wykorzystamy kNN. Dla 1, 5 i 9 sąsiadów. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ0yEabjiHjx",
        "outputId": "9c8e322b-e375-43b7-d0e9-6bce1c277249"
      },
      "source": [
        "# model.fit(x,y) - zajmuje się dopasowaniem modelu do danych\n",
        "KNN_model_k_1 = KNeighborsClassifier(n_neighbors=1).fit(X_train_1, y_train_1)\n",
        "confusion_matrix(KNN_model_k_1.predict(X_train_1), y_train_1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4042,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0, 4051,    0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0, 3916,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0, 4016,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0, 3971,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0, 3976,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0, 4013,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0, 4002,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0, 4055,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 3958]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpmzNwE6iQPf",
        "outputId": "a5858731-3304-4680-9248-fc4a0012c23d"
      },
      "source": [
        "# ocena dokładności \n",
        "KNN_model_k_1_accuracy = (KNN_model_k_1.predict(X_train_1) == y_train_1).mean()\n",
        "print(\"TRAINING ACCURACY FOR N = 1:\", KNN_model_k_1_accuracy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING ACCURACY: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYLYsDXTjMT0",
        "outputId": "0acb6a69-8b86-46e6-aab3-0b8be67c58cf"
      },
      "source": [
        "# prognozowanie na danych walidaycjnych\n",
        "predictions_array = confusion_matrix(KNN_model_k_1.predict(x_valid_1), y_valid_1)\n",
        "print(predictions_array)\n",
        "# Znajdowanie klasy o największym prawdopodobieństwie wystąpienia w prognozie \n",
        "max_prawd = np.argmax(predictions_array[0]))\n",
        "print(f'Najczęsciej wystepującym ubraniem jest: {class_clothes[max_prawd]}')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[802   2  16  35   8   2 172   0   7   0]\n",
            " [  3 922   0   4   1   0   1   0   0   0]\n",
            " [ 26   2 833   8 117   0 128   0  10   1]\n",
            " [ 21  16   9 834  33   0  23   0   2   0]\n",
            " [  4   1 107  31 745   0  67   0   6   0]\n",
            " [  1   0   0   0   0 866   0   5   0   2]\n",
            " [128   5  98  45 105   3 625   0  14   0]\n",
            " [  0   0   0   0   0  79   0 971   1  29]\n",
            " [  3   0   1   2   2   4   4   0 908   1]\n",
            " [  0   0   1   0   0  48   0  63   3 984]]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IMQozUwz4J8",
        "outputId": "5d9a0466-a9a8-4c6a-e212-c1ecba5c8da5"
      },
      "source": [
        "max_prawd = np.argmax(predictions_array[0])\n",
        "print(class_clothes[max_prawd])\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "T-shirt/top\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GCoRIQmjZG0",
        "outputId": "aa40d0bf-cfe7-44c1-83f4-95a80aa550f8"
      },
      "source": [
        "# ocena dokładności prognozy na danych walidacyjnych \n",
        "KNN_model_k_1_accuracy = (KNN_model_k_1.predict(x_valid_1) == y_valid_1).mean()\n",
        "print(\"VALIDATION ACCURACY for n = 1 :\", KNN_model_k_1_accuracy)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING ACCURACY for n = 1 : 0.849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXhzr5nRmD91"
      },
      "source": [
        "Gdy przyjmujemy jako ilość sąsiadów k = 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy9NZPsclwmV"
      },
      "source": [
        "start = time.clock()\n",
        "KNN_model_k_5 = KNeighborsClassifier(n_neighbors=5).fit(X_train_1, y_train_1)\n",
        "macierz_5 = confusion_matrix(KNN_model_k_5.predict(X_train_1), y_train_1)\n",
        "\n",
        "print(macierz_5)\n",
        "print(np.argmax(macierz_5[0]))\n",
        "print(class_clothes[np.argmax(macierz_5[0])])\n",
        "KNN_model_k_5_accuracy = (KNN_model_k_5.predict(X_train_1) == y_train_1).mean()\n",
        "print(\"TRAINING ACCURACY FOR N = 5:\", KNN_model_k_5_accuracy)\n",
        "\n",
        "KNN_model_k_5_accuracy = (KNN_model_k_5.predict(X_valid_1) == y_valid_1).mean()\n",
        "confusion_matrix(KNN_model_k_5.predict(x_valid_1), y_valid_1)\n",
        "print(\"VALIDATION ACCURACY FOR n = 5:\", KNN_model_k_5_accuracy)\n",
        "end = time.clock()\n",
        "total = end - start\n",
        "print(f'time:{total/60}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0DkHnGKeCRL"
      },
      "source": [
        "Gdy przyjmujemyjako ilość sądiadów k = 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIaWfS407af5",
        "outputId": "f354df80-97d3-4442-8039-13b83d27fd50"
      },
      "source": [
        "# rozpoczęcie liczenia czasu\n",
        "start = time.clock()\n",
        "# dopasowanie modalu kNN z k = 9  dla danych \n",
        "KNN_model_k_9 = KNeighborsClassifier(n_neighbors=9).fit(X_train_1, y_train_1)\n",
        "macierz_9 = confusion_matrix(KNN_model_k_9.predict(X_train_1) == y_train_1).mean()\n",
        "print(macierz_9)\n",
        "print(np.argmax(macierz_9[0]))\n",
        "print(f'Najczęsciej występującym ubraniem jest: {class_clothes[np.argmax(macierz_9[0])]}')\n",
        "KNN_model_k_9_accuracy = (KNN_model_k_9.predict(X_train_1) == y_train_1).mean()\n",
        "print(\"TRAINING ACCURACY FOR N = 5:\", KNN_model_k_5_accuracy)\n",
        "# prognozowanie na danych walidacyjnych\n",
        "KNN_model_k_9_accuracy = (KNN_model_k_9.predict(X_train_1) == y_train_1).mean()\n",
        "print(confusion_matrix(KNN_model_k_9.predict(x_valid_1), y_valid_1))\n",
        "print(\"VALIDATTION ACCURACY for n = 9 :\", KNN_model_k_9_accuracy)\n",
        "end = time.clock()\n",
        "# zakończenie liczenia czasu\n",
        "total = end - start\n",
        "print(f'time:{total/60}' )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING ACCURACY: 0.873575\n",
            "time:70.40844191666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s23V3L-WE6rR"
      },
      "source": [
        "Fitting Gradient Boosting - metoda wykorzystująca  boosting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4jdQFPuLWwp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}